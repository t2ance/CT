# Configuration for CT Super-Resolution with Latent Diffusion
# Model: 3D UNet Diffusion in VQ-AE Latent Space
# Last updated: 2025-01-12 (Fixed data_range bug)

# Data configuration
data:
  # Path to cached latent representations (pre-encoded by VQ-AE)
  latent_cache_dir: "./latents_cache"

  # VQ-AE checkpoint for decoding (visualization & metrics)
  vae_checkpoint: "/data2/peijia/projects/BioAgent/3D-MedDiffusion/checkpoints/PatchVolume_8x_s2.ckpt"

  # Latent normalization (keep False - latents are ~[-30, 30])
  normalize_latents: false

  # Expected latent shape (after VQ-AE encoding)
  # Example: [200, 128, 128] CT → [25, 16, 16] latent (8× compression)
  latent_channels: 8 # Cℓ from VQ-AE

# Model architecture (3D UNet for diffusion)
model:
  # Base model channels (scaled up from 64 for better performance)
  model_channels: 128  # Was 64 (SCALED UP)

  # Channel multipliers per resolution level
  channel_mult: [4, 4]  # Was [1, 2, 4, 4] (SCALED UP)

  # Number of ResNet blocks per level
  num_blocks: 5  # Was 2 (SCALED UP)

  # Which levels get attention (0=highest res, 3=lowest res)
  attention_levels: [1]  # Was [2, 3] (MORE ATTENTION)

  # Time embedding dimension
  time_embed_dim: 512  # Was 256 (SCALED UP)

  # Dropout for regularization
  dropout: 0  # Was 0.0 (ADDED DROPOUT)

  # Number of attention heads
  num_heads: 8

  # Input/output channels (latent space)
  in_channels: 8  # LDCT latent
  out_channels: 8  # HDCT latent (predict noise in latent space)

  # Conditioning: concatenate LDCT latent to HDCT latent
  concat_conditioning: true

  # Optional FlashAttention acceleration (requires CUDA + flash-attn package)
  use_flash_attention: true

# Diffusion scheduler
scheduler:
  # Training timesteps (T in DDPM paper)
  num_train_timesteps: 1000

  # Beta schedule for noise
  beta_schedule: "linear" # 'linear' or 'scaled_linear'
  beta_start: 0.0001
  beta_end: 0.02

  # Prediction type
  prediction_type: "epsilon" # Predict noise (standard DDPM)

  # Don't clip samples (latent space is ~[-30, 30])
  clip_sample: false

# Training configuration
training:
  batch_size: 48
  # batch_size: 4
  seed: 42

  gradient_accumulation_steps: 1

  num_epochs: 1000

  # Optimizer
  learning_rate: 1.0e-4
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1.0e-8
  weight_decay: 0.03

  # Learning rate scheduler
  lr_scheduler_type: "linear" # 'linear' with warmup
  warmup_ratio: 0.06 # 6% of total steps for warmup
  lr_min: 0.0 # Minimum LR after decay

  # Mixed precision training
  mixed_precision: "bf16" # 'fp16', 'bf16', or 'no'

  # Gradient clipping
  max_grad_norm: 1.0

  # Validation and checkpointing
  val_every: 100 # Lightweight validation (MSE only)
  save_every: 100 # Save checkpoint every N steps

  # Number of dataloader workers
  num_workers: 8

  # Logging
  log_every: 1 # Log metrics every N steps
  use_wandb: true
  wandb_project: "ct-diffusion"
  wandb_entity: null # Set to your wandb username
  wandb_run_name: null # Auto-generated if null
  wandb_tags: ["latent-diffusion", "ct", "3d"]
  
  

# Validation configuration (for SSIM/PSNR metrics)
validation:
  # Two-tier validation strategy:
  # - Lightweight: Only MSE loss (fast, every val_every steps)
  # - Full: SSIM + PSNR metrics (slow, every full_val_every steps)

  # Full validation settings
  enable_full_validation: true # Enable SSIM/PSNR metrics
  full_val_every: 100 # Run full validation every N steps (slower)
  num_samples: 32 # Number of validation samples to evaluate (4-8 recommended)

  # Metrics settings
  data_range:
    2.0 # VQ-AE output range for SSIM/PSNR (normalized to ~[-1, 1])

  compute_slice_wise: true # Compute metrics slice-wise (more robust for 3D)

  # Distributed evaluation
  distributed_eval: true # Enable distributed evaluation across GPUs

# Inference configuration
inference:
  # DDIM sampling (faster than DDPM)
  use_ddim: true
  num_inference_steps: 100 # Was 50 (can increase for quality)

  # Guidance scale (for classifier-free guidance, if implemented)
  guidance_scale: 1.0 # 1.0 = no guidance

# Output directories
output:
  # Where to save checkpoints and logs
  checkpoint_dir: "./outputs/checkpoints"
  log_dir: "./outputs/logs"
  visualization_dir: "./outputs/visualizations"

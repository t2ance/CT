Traceback (most recent call last):
Traceback (most recent call last):
  File "/data2/peijia/projects/ct/train_diffusion.py", line 52, in <module>
    from models.vqae_wrapper import FrozenVQAE
  File "/data2/peijia/projects/ct/train_diffusion.py", line 52, in <module>
    from models.vqae_wrapper import FrozenVQAE
  File "/data2/peijia/projects/ct/models/__init__.py", line 5, in <module>
    from .vqae_wrapper import FrozenVQAE
  File "/data2/peijia/projects/ct/models/__init__.py", line 5, in <module>
    from .vqae_wrapper import FrozenVQAE
  File "/data2/peijia/projects/ct/models/vqae_wrapper.py", line 21, in <module>
    from AutoEncoder.model.PatchVolume import patchvolumeAE
  File "/data2/peijia/projects/ct/third_party/3d_meddiffusion/AutoEncoder/model/PatchVolume.py", line 16, in <module>
    from einops_exts import  rearrange_many
  File "/data2/peijia/projects/ct/models/vqae_wrapper.py", line 21, in <module>
    from AutoEncoder.model.PatchVolume import patchvolumeAE
  File "/data2/peijia/projects/ct/third_party/3d_meddiffusion/AutoEncoder/model/PatchVolume.py", line 16, in <module>
    from einops_exts import  rearrange_many
ModuleNotFoundError: No module named 'einops_exts'
ModuleNotFoundError: No module named 'einops_exts'
W1013 15:32:48.632000 821947 /data2/peijia/miniconda3/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 822042 closing signal SIGTERM
E1013 15:32:48.664000 821947 /data2/peijia/miniconda3/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 1 (pid: 822043) of binary: /home/peijia/miniconda3/bin/python
Traceback (most recent call last):
  File "/home/peijia/miniconda3/bin/accelerate", line 7, in <module>
    sys.exit(main())
             ~~~~^^
  File "/home/peijia/miniconda3/lib/python3.13/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
    ~~~~~~~~~^^^^^^
  File "/home/peijia/miniconda3/lib/python3.13/site-packages/accelerate/commands/launch.py", line 1222, in launch_command
    multi_gpu_launcher(args)
    ~~~~~~~~~~~~~~~~~~^^^^^^
  File "/home/peijia/miniconda3/lib/python3.13/site-packages/accelerate/commands/launch.py", line 853, in multi_gpu_launcher
    distrib_run.run(args)
    ~~~~~~~~~~~~~~~^^^^^^
  File "/home/peijia/miniconda3/lib/python3.13/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
    ~~~~~~~~~~~~~~~
        config=config,
        ~~~~~~~~~~~~~~
        entrypoint=cmd,
        ~~~~~~~~~~~~~~~
    )(*cmd_args)
    ~^^^^^^^^^^^
  File "/home/peijia/miniconda3/lib/python3.13/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/peijia/miniconda3/lib/python3.13/site-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
    raise ChildFailedError(
    ...<2 lines>...
    )
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train_diffusion.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-13_15:32:48
  host      : ecepxiegpu2
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 822043)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================

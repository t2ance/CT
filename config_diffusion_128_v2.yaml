data:
  hub_repo: "t2ance/ct-diffusion-128"

  cache_dir: "/data1/peijia/ct"

  vae_checkpoint: "checkpoints/PatchVolume_8x_s2.ckpt"

  normalize_latents: false

  latent_channels: 8

model:
  model_channels: 32
  channel_mult: [1, 2, 4]
  num_blocks: 2
  attention_levels: [1, 2]
  time_embed_dim: 256
  dropout: 0.3
  num_heads: 8
  in_channels: 8
  out_channels: 8

  concat_conditioning: true

  use_flash_attention: true

scheduler:
  num_train_timesteps: 1000
  beta_schedule: "linear"
  beta_start: 0.0001
  beta_end: 0.02

  prediction_type: "epsilon"

  clip_sample: false

training:
  train_batch_size: 256
  eval_batch_size: 32
  seed: 42
  gradient_accumulation_steps: 1
  num_epochs: 15000
  learning_rate: 1.0e-4
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1.0e-8
  weight_decay: 0.3
  lr_scheduler_type: "linear"
  warmup_ratio: 0.08
  lr_min: 0.0
  mixed_precision: "bf16"
  max_grad_norm: 1.0
  save_every: 10000
  val_every: 500
  num_workers: 16
  log_every: 1
  use_wandb: true
  wandb_project: "ct-diffusion"
  wandb_entity: null
  wandb_run_name: 128_v2
  wandb_tags: ["latent-diffusion", "ct", "3d", "scaled-up"]

validation:
  compute_train_metrics: true
  num_samples: 32

  num_visualizations: 1

  data_range: 2.0
  compute_slice_wise: true
  spatial_chunk_size: 32
  distributed_eval: true

inference:
  use_ddim: true
  num_inference_steps: 100
  guidance_scale: 1.0

output:
  checkpoint_dir: "./outputs/checkpoints"
  log_dir: "./outputs/logs"
  visualization_dir: "./outputs/visualizations"
